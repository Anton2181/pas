# Tango task distributor

This repo houses the offline pipeline that schedules weekly tango school tasks. The data snapshots in the root (CSV + backend metadata) are kept up to date so you can run the encoder + solver locally without hitting Google Sheets.

## Workflow overview

1. `python3 extractor.py`
   - Pulls the latest Google Sheet export when needed and refreshes `components_all.csv` / `backend.csv`.
   - The checked-in CSVs already contain the dataset that triggered the current round of debugging, so you can skip this step unless you have new data.
2. `python3 encode_sat_from_components.py`
   - Builds `schedule.opb`, `varmap.json`, and `stats.txt`.
   - Automatically widens candidate pools via leader/follower sibling links, merges "Both" role expansions, and reports which families are scarcity-limited (see `auto_soften_families` in `varmap.json`).
3. `python3 run_solver.py --opb schedule.opb --log logs/solver.log`
   - Runs SAT4J with a **hard 120s timeout** so the workflow never hangs. Adjust `--timeout` if you want a different wall clock limit. The wrapper mirrors stdout to the terminal and to the specified log file, returning exit code `124` when it kills the solver.
   - Every `v ...` model that SAT4J prints is captured automatically. The wrapper writes them to `models.txt` and immediately invokes `consume_saved_models.py` so `assigned_optimal.csv`, `models_summary.csv`, `loads_by_person.csv`, `fairness_plots_*.png`, and `penalties_activated.csv` are refreshed without manual copy/paste. Pass `--skip-consume` if you only want the solver log. (If the solver times out before it emits a `v ...` line, the wrapper keeps the log and reports that no evaluation was run.)

## Encoder details

- Soft constraints such as cooldown ladders, repeat caps, and fairness tiers are documented in `docs/encoder.md`.
- `stats.txt` now records whether auto-softening skipped any penalties for candidate-starved families. Combine that list with `penalties_activated.csv` to see whether the remaining penalties concentrate in better-staffed families.
- `varmap.json` contains every objective selector plus a copy of `CONFIG`, so it is the single source of truth for the weights used in each run.

## When something looks off

1. **Penalties feel unreasonably high even when weights change.** Check `varmap.json.auto_soften_families`. Families that do *not* appear there still pay full cooldown/repeat costs; if they only have one or two eligible people, widen their candidate pool in `components_all.csv` or the backend roles so they qualify for auto-softening.
2. **Solver output takes too long.** Re-run via `python3 run_solver.py --timeout 90` (or any limit you prefer). The wrapper will stop SAT4J automatically and still extract the best-known `v ...` line so the downstream CSVs stay in sync.
3. **Need more context?** `docs/encoder.md` describes every artifact the encoder produces and how to inspect it.
