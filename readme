# Tango task distributor

This repo houses the offline pipeline that schedules weekly tango school tasks. The data snapshots in the root (CSV + backend metadata) are kept up to date so you can run the encoder + solver locally without hitting Google Sheets.

## Workflow overview

1. `python3 extractor.py`
   - Pulls the latest Google Sheet export when needed and refreshes `components_all.csv` / `backend.csv`.
   - The checked-in CSVs already contain the dataset that triggered the current round of debugging, so you can skip this step unless you have new data.
2. `python3 encode_sat_from_components.py`
   - Builds `schedule.opb`, `varmap.json`, and `stats.txt`.
   - Automatically widens candidate pools via leader/follower sibling links, merges "Both" role expansions, and reports which families are scarcity-limited (see `auto_soften_families` in `varmap.json`).
3. `python3 run_solver.py --opb schedule.opb --log logs/solver.log`
   - Runs SAT4J with a **hard 120s timeout** so the workflow never hangs. Adjust `--timeout` if you want a different wall clock limit. The wrapper mirrors stdout to the terminal and to the specified log file, returning exit code `124` when it kills the solver.
4. Paste the solverâ€™s `v ...` model into `models.txt` and summarize it via
   ```bash
   python3 consume_saved_models.py \
       --models models.txt \
       --varmap varmap.json \
       --components components_all.csv \
       --metric effort \
       --plots-bars fairness_plots_bars.png \
       --plots-lorenz fairness_plots_lorenz.png \
       --assigned-out assigned_optimal.csv \
       --models-out models_summary.csv \
       --loads-out loads_by_person.csv
   ```
   The resulting CSVs and charts drive the fairness/debug review.

## Encoder details

- Soft constraints such as cooldown ladders, repeat caps, and fairness tiers are documented in `docs/encoder.md`.
- `stats.txt` now records whether auto-softening skipped any penalties for candidate-starved families. Combine that list with `penalties_activated.csv` to see whether the remaining penalties concentrate in better-staffed families.
- `varmap.json` contains every objective selector plus a copy of `CONFIG`, so it is the single source of truth for the weights used in each run.

## When something looks off

1. **Penalties feel unreasonably high even when weights change.** Check `varmap.json.auto_soften_families`. Families that do *not* appear there still pay full cooldown/repeat costs; if they only have one or two eligible people, widen their candidate pool in `components_all.csv` or the backend roles so they qualify for auto-softening.
2. **Solver output takes too long.** Re-run via `python3 run_solver.py --timeout 90` (or any limit you prefer). The wrapper will stop SAT4J automatically, keeping the best-known model in the log so you can paste it into `models.txt`.
3. **Need more context?** `docs/encoder.md` describes every artifact the encoder produces and how to inspect it.
